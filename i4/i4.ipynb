{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXyaHhoahuqrPTtwTjqS8/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chocograhams/IMT542/blob/main/i4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Example 1**\n",
        "\n",
        "**Information Structure**: CSV\n",
        "\n",
        "**Access Technology**: Manual file upload and read locally in Colab\n",
        "\n",
        "**Description:** Reads CSV data from file (Repeat tags cleaned_SeaCoyottee - SME Highlights 2025-02-09 20_41.csv) uploadeded to Google Colab and prints the 20 most commonly repeated phrases consisting three words. This is also a text mining script.\n",
        "\n",
        "**Pros:**\n",
        "*   CSV is a simple and widely used format for tabular data\n",
        "*   Uploading files to Colab is straightforward\n",
        "*   The 'csv' module is built into Python, no extra installations needed\n",
        "*   Allows working with data you might have locally\n",
        "\n",
        "**Cons:**\n",
        "*   Requires the user to manually upload the file each session\n",
        "*   Data is static unless the uploaded file is changed\n",
        "*   No inherent complex structure beyond rows and columns\n"
      ],
      "metadata": {
        "id": "CoC2-cUTKzV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "def find_top_phrases(filename=\"/content/Repeat tags cleaned_SeaCoyottee - SME Highlights 2025-02-09 20_41.csv\", top_n=20):\n",
        "    try:\n",
        "        df = pd.read_csv(filename)  # Assuming the CSV has a relevant text column\n",
        "\n",
        "        if 'Text' not in df.columns:\n",
        "            print(\"Error: 'text' column not found in the CSV. Please ensure the CSV has a column named 'text' containing the text data.\")\n",
        "            return\n",
        "\n",
        "        all_text = ' '.join(df['Text'].astype(str).tolist()).lower() # Combine all text and lowercase\n",
        "\n",
        "        words = all_text.split()\n",
        "        noun_verb_phrases = []\n",
        "\n",
        "        # Basic phrase extraction\n",
        "        for i in range(len(words) - 2):  # Iterate over 3-word windows\n",
        "            noun_verb_phrases.append(tuple(words[i:i+3]))\n",
        "\n",
        "        phrase_counts = Counter(noun_verb_phrases)\n",
        "\n",
        "        # Print top N phrases\n",
        "        print(f\"Top {top_n} 3-word phrases:\")\n",
        "        for phrase, count in phrase_counts.most_common(top_n):\n",
        "            print(f\"{phrase}: {count}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filename}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  find_top_phrases()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enocO3TQge5C",
        "outputId": "44e08210-dd0a-4bb4-8a06-69f7df0140ef"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 3-word phrases:\n",
            "('a', 'lot', 'of'): 20\n",
            "('i', 'mean,', 'i'): 12\n",
            "('a', 'little', 'bit'): 8\n",
            "('the', 'city', 'of'): 7\n",
            "('lot', 'of', 'people'): 7\n",
            "('i', \"don't\", 'know'): 6\n",
            "('in', 'their', 'neighborhood'): 6\n",
            "('there', 'was', 'a'): 6\n",
            "('little', 'bit', 'more'): 5\n",
            "('things', 'like', 'that.'): 5\n",
            "('yeah,', 'i', 'think'): 5\n",
            "('you', 'never', 'know'): 5\n",
            "('but', 'i', \"don't\"): 5\n",
            "('you', 'know,', 'i'): 4\n",
            "('i', \"don't\", 'have'): 4\n",
            "('i', 'would', 'just'): 4\n",
            "('just', 'like', 'a'): 4\n",
            "('city', 'of', 'seattle'): 4\n",
            "('i', 'think', 'those'): 4\n",
            "('of', 'people', \"don't\"): 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2\n",
        "\n",
        "**Information Structure**: JSON\n",
        "\n",
        "**Access Technology**: API connection over HTTP\n",
        "\n",
        "**Description**: Fetches JSON data from a public API and prints sample.\n",
        "\n",
        "**Pros:**\n",
        "*   Many public APIs offer free and easily accessible data\n",
        "*   The 'requests' library is often pre-installed in Colab\n",
        "*   JSON is a common and relatively easy-to-understand data format\n",
        "*   No local file management needed initially\n",
        "\n",
        "**Cons**:\n",
        "*   Requires an internet connection\n",
        "*   API availability and structure can change\n",
        "*   Some APIs might have rate limits"
      ],
      "metadata": {
        "id": "6TSiD8g1Vp-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def get_and_print_json_from_api():\n",
        "\n",
        "    api_url = \"https://api.thecatapi.com/v1/images/search\"\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes\n",
        "        json_data = response.json()\n",
        "        print(\"JSON data from API:\")\n",
        "        print(json_data)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from API: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    get_and_print_json_from_api()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9cKnT_1Kxft",
        "outputId": "3a04b7a0-d85c-4126-a234-0cbee2530ead"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON data from API:\n",
            "[{'id': 'cp3', 'url': 'https://cdn2.thecatapi.com/images/cp3.jpg', 'width': 640, 'height': 480}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3\n",
        "**Information Structure**: HTML\n",
        "\n",
        "**Access Technology**: HTTP to download webpage (using requests) and basic parsing\n",
        "\n",
        "**Description**:Downloads an HTML webpage using HTTP and prints its title and the text content of the first, second, and third paragraphs.\n",
        "\n",
        "**Pros**:\n",
        "*   Demonstrates fetching data from the internet beyond structured APIs\n",
        "*   'requests' is often pre-installed in Colab.\n",
        "\n",
        "**Cons**:\n",
        "*   Requires an internet connection\n",
        "*   HTML structure variability can make consistent data extraction challenging\n",
        "*   Even this slightly more complex extraction requires understanding basic HTML tags\n",
        "*   Requires installing 'beautifulsoup4'\n"
      ],
      "metadata": {
        "id": "83AGsonKW8fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_and_print_multiple_paragraphs(url=\"https://www.gutenberg.org/about/background/50years.html\"):\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract the title\n",
        "        title_tag = soup.find('title')\n",
        "        title = title_tag.string.strip() if title_tag and title_tag.string else \"No title found\"\n",
        "        print(f\"\\nDetails from webpage at {url}:\")\n",
        "        print(f\"Title: {title}\")\n",
        "\n",
        "        # Extract the first two paragraphs\n",
        "        paragraph_tags = soup.find_all('p', limit=3)  # Find the first 3 <p> tags\n",
        "\n",
        "        if paragraph_tags:\n",
        "            for i, p_tag in enumerate(paragraph_tags):\n",
        "                paragraph_text = p_tag.text.strip()\n",
        "                print(f\"Paragraph {i+1}: {paragraph_text}\")\n",
        "\n",
        "        elif len(paragraph_tags) == 1:\n",
        "            paragraph_text = paragraph_tags[0].text.strip()\n",
        "            print(f\"Paragraph 1: {paragraph_text}\")\n",
        "            print(\"Only one paragraph tag found on this webpage.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching webpage at {url}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the webpage: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Make sure you have installed beautifulsoup4 in Colab:\n",
        "    # !pip install beautifulsoup4\n",
        "    get_and_print_multiple_paragraphs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54On-MbMbA5h",
        "outputId": "e85e3c3d-cb91-42f8-ad34-b8a218aff9e2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Details from webpage at https://www.gutenberg.org/about/background/50years.html:\n",
            "Title: 50 years of eBooks 1971-2021 | Project Gutenberg\n",
            "Paragraph 1: Ways to donate\n",
            "Paragraph 2: July 4, 2021 – In 1997, Time-Life magazine picked the movable type printing press as the most important invention of the second millennium. Like most important innovations and social changes, the printing press was an evolution that had deep roots in history.\n",
            "Paragraph 3: Move forward in time to 1971, when Michael Hart invented the eBook. Like Gutenberg’s printing press, Hart’s innovation followed decades of prior work. To name a few, this includes Vannevar Bush’s “Memex” (1930s, based on microfiche), Bob Brown’s “The Readies” (1930s), Brown University’s “FRESS” (1960s), Ted Nelson’s Xanadu (1960s), and many others.\n"
          ]
        }
      ]
    }
  ]
}
